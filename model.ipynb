{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10fbe072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100006 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "dataset = tf.keras.utils.text_dataset_from_directory(\n",
    "    directory=\"dataset/aclImdb\", label_mode=None, batch_size=16)\n",
    "dataset = dataset.map(lambda x: tf.strings.regex_replace(x, \"<br />\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c954476",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "vocab_size = 15000\n",
    "text_vectorization = TextVectorization(\n",
    " max_tokens=vocab_size, \n",
    " output_mode=\"int\",\n",
    " output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "text_vectorization.adapt(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c746cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lm_dataset(text_batch):\n",
    "    vectorized_sequences = text_vectorization(text_batch)\n",
    "    x = vectorized_sequences[:, :-1] \n",
    "    y = vectorized_sequences[:, 1:]\n",
    "    return x, y\n",
    " \n",
    "lm_dataset = dataset.map(prepare_lm_dataset, num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74a5d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = Embedding(\n",
    "        input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = Embedding(\n",
    "        input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "        \"output_dim\": self.output_dim,\n",
    "        \"sequence_length\": self.sequence_length,\n",
    "        \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec3c822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = Sequential(\n",
    "        [Dense(dense_dim, activation=\"relu\"),\n",
    "        Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = LayerNormalization()\n",
    "        self.layernorm_2 = LayerNormalization()\n",
    "        self.layernorm_3 = LayerNormalization()\n",
    "        self.supports_masking = True \n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "        \"embed_dim\": self.embed_dim,\n",
    "        \"num_heads\": self.num_heads,\n",
    "        \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "        [tf.expand_dims(batch_size, -1),\n",
    "        tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "    \n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(\n",
    "            mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "            attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask) \n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "        query=attention_output_1,\n",
    "        value=encoder_outputs,\n",
    "        key=encoder_outputs,\n",
    "        attention_mask=padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "        attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30e6c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 2\n",
    " \n",
    "    \n",
    "inputs = Input(shape=(None,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, x)\n",
    "outputs = Dense(vocab_size, activation=\"softmax\")(x)\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "795b6061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[5.6872628e-05 7.7745863e-05 6.0421706e-05 ... 6.7597241e-05\n",
      "   5.0602208e-05 6.4274202e-05]\n",
      "  [8.2555176e-05 7.1145092e-05 7.0926937e-05 ... 8.4092244e-05\n",
      "   5.6250094e-05 6.0516690e-05]\n",
      "  [4.2434371e-05 6.0013474e-05 6.8193382e-05 ... 6.1311664e-05\n",
      "   5.8396021e-05 7.2625560e-05]\n",
      "  ...\n",
      "  [8.9070498e-05 7.4948475e-05 7.5644319e-05 ... 7.3166972e-05\n",
      "   6.5437118e-05 9.8309480e-05]\n",
      "  [6.7717468e-05 7.5312761e-05 8.1382605e-05 ... 7.2559422e-05\n",
      "   5.5656012e-05 5.9775815e-05]\n",
      "  [8.0875354e-05 5.5514058e-05 6.4606735e-05 ... 5.3243733e-05\n",
      "   7.9286787e-05 5.7814676e-05]]\n",
      "\n",
      " [[5.1716728e-05 7.8366524e-05 7.6930839e-05 ... 5.3837302e-05\n",
      "   5.1387127e-05 5.1262221e-05]\n",
      "  [8.8077264e-05 8.4596832e-05 9.1060028e-05 ... 7.7747274e-05\n",
      "   7.9454992e-05 4.0142681e-05]\n",
      "  [5.0106588e-05 5.0674429e-05 7.2785704e-05 ... 5.7358291e-05\n",
      "   5.5386674e-05 4.9088201e-05]\n",
      "  ...\n",
      "  [6.8918343e-05 9.5390904e-05 7.4481286e-05 ... 6.1743151e-05\n",
      "   7.7927391e-05 7.5718817e-05]\n",
      "  [5.0077619e-05 6.0434089e-05 8.5545995e-05 ... 7.1152986e-05\n",
      "   4.8254282e-05 6.5653599e-05]\n",
      "  [6.8252557e-05 6.6384528e-05 8.4970517e-05 ... 7.4210664e-05\n",
      "   6.1173465e-05 5.7556208e-05]]\n",
      "\n",
      " [[5.1716728e-05 7.8366524e-05 7.6930839e-05 ... 5.3837302e-05\n",
      "   5.1387127e-05 5.1262221e-05]\n",
      "  [9.1641079e-05 8.7537759e-05 5.3199416e-05 ... 7.4191128e-05\n",
      "   6.8177651e-05 7.4631826e-05]\n",
      "  [4.9409180e-05 7.3695715e-05 8.7781991e-05 ... 6.8922403e-05\n",
      "   6.6096705e-05 5.8241156e-05]\n",
      "  ...\n",
      "  [6.4404419e-05 8.6103079e-05 5.3460535e-05 ... 5.7460307e-05\n",
      "   8.2877727e-05 9.0267589e-05]\n",
      "  [5.2040774e-05 7.0922652e-05 6.1722945e-05 ... 6.7730965e-05\n",
      "   5.1459290e-05 7.8517303e-05]\n",
      "  [6.9929352e-05 6.8599482e-05 5.4582008e-05 ... 5.6356977e-05\n",
      "   6.4110121e-05 7.0252194e-05]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[5.8098791e-05 6.5426779e-05 5.7275887e-05 ... 6.7050802e-05\n",
      "   5.1795032e-05 5.0451701e-05]\n",
      "  [7.1810668e-05 9.4203424e-05 7.6376935e-05 ... 9.3675721e-05\n",
      "   6.8288427e-05 5.6604549e-05]\n",
      "  [5.1170759e-05 6.0309187e-05 7.8724930e-05 ... 6.4859683e-05\n",
      "   4.2962773e-05 5.6826691e-05]\n",
      "  ...\n",
      "  [7.7751443e-05 7.9295030e-05 7.3582065e-05 ... 4.6737416e-05\n",
      "   8.0728554e-05 7.5092721e-05]\n",
      "  [5.8829391e-05 7.1190458e-05 9.1264053e-05 ... 9.1315233e-05\n",
      "   5.1423805e-05 5.1045306e-05]\n",
      "  [7.4361618e-05 5.7483219e-05 5.4783948e-05 ... 5.3713000e-05\n",
      "   6.5330183e-05 6.7208835e-05]]\n",
      "\n",
      " [[4.5312590e-05 8.1091777e-05 6.7401954e-05 ... 6.4286207e-05\n",
      "   5.3433527e-05 6.6665736e-05]\n",
      "  [7.9423189e-05 6.5887034e-05 7.2239185e-05 ... 9.1577225e-05\n",
      "   6.2755003e-05 5.8868631e-05]\n",
      "  [6.3064712e-05 6.0295210e-05 6.1687286e-05 ... 6.6517438e-05\n",
      "   6.5334440e-05 7.8292302e-05]\n",
      "  ...\n",
      "  [8.2766564e-05 6.7498288e-05 6.2437313e-05 ... 5.7061261e-05\n",
      "   6.5675733e-05 8.7451161e-05]\n",
      "  [5.8509348e-05 5.6535529e-05 7.6036857e-05 ... 8.6814718e-05\n",
      "   4.4318087e-05 6.0632021e-05]\n",
      "  [8.7772532e-05 5.5193970e-05 6.6595734e-05 ... 6.3752108e-05\n",
      "   6.6595501e-05 8.8190900e-05]]\n",
      "\n",
      " [[6.6333057e-05 7.1505383e-05 6.9828078e-05 ... 6.5451975e-05\n",
      "   4.8629350e-05 5.9294322e-05]\n",
      "  [8.7967739e-05 7.0886381e-05 8.1112834e-05 ... 8.0425882e-05\n",
      "   6.7985718e-05 6.1217630e-05]\n",
      "  [5.8970450e-05 6.4325242e-05 9.3209805e-05 ... 6.6205786e-05\n",
      "   7.6965633e-05 6.0607850e-05]\n",
      "  ...\n",
      "  [8.7570173e-05 8.6984735e-05 6.0761740e-05 ... 5.3345386e-05\n",
      "   8.9423840e-05 6.5754553e-05]\n",
      "  [5.8971928e-05 7.0450144e-05 6.2642233e-05 ... 7.2319766e-05\n",
      "   5.4071577e-05 7.1128481e-05]\n",
      "  [7.2987095e-05 6.5766872e-05 8.2313156e-05 ... 6.4833330e-05\n",
      "   5.8371370e-05 5.1343213e-05]]], shape=(16, 99, 15000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in lm_dataset.take(1):\n",
    "    print(model(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84baf62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tokens_index = dict(enumerate(text_vectorization.get_vocabulary()))\n",
    " \n",
    "def sample_next(predictions, temperature=1.0):\n",
    "    predictions = np.asarray(predictions).astype(\"float64\")\n",
    "    predictions = np.log(predictions) / temperature\n",
    "    exp_preds = np.exp(predictions)\n",
    "    predictions = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, predictions, 1)\n",
    "    return np.argmax(probas)\n",
    " \n",
    "class TextGenerator(Callback):\n",
    "    def __init__(self,\n",
    "            prompt,\n",
    "            generate_length,\n",
    "            model_input_length,\n",
    "            temperatures=(1.,),\n",
    "            print_freq=1):\n",
    "        self.prompt = prompt\n",
    "        self.generate_length = generate_length\n",
    "        self.model_input_length = model_input_length\n",
    "        self.temperatures = temperatures\n",
    "        self.print_freq = print_freq\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.print_freq != 0:\n",
    "            return\n",
    "        for temperature in self.temperatures:\n",
    "            print(\"== Generating with temperature\", temperature)\n",
    "            sentence = self.prompt\n",
    "            for i in range(self.generate_length):\n",
    "                tokenized_sentence = text_vectorization([sentence])\n",
    "                predictions = self.model(tokenized_sentence)\n",
    "                next_token = sample_next(predictions[0, i, :])\n",
    "                sampled_token = tokens_index[next_token]\n",
    "                sentence += \" \" + sampled_token\n",
    "            print(sentence)\n",
    "prompt = \"This movie\"\n",
    "text_gen_callback = TextGenerator(\n",
    "     prompt,\n",
    "     generate_length=50,\n",
    "     model_input_length=sequence_length,\n",
    "     temperatures=(0.2, 0.5, 0.7, 1., 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ebf7b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " positional_embedding_4 (Positi  (None, None, 256)   3865600     ['input_5[0][0]']                \n",
      " onalEmbedding)                                                                                   \n",
      "                                                                                                  \n",
      " transformer_decoder_4 (Transfo  (None, None, 256)   2104576     ['positional_embedding_4[0][0]', \n",
      " rmerDecoder)                                                     'positional_embedding_4[0][0]'] \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, None, 15000)  3855000     ['transformer_decoder_4[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,825,176\n",
      "Trainable params: 9,825,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "6251/6251 [==============================] - ETA: 0s - loss: 5.1440== Generating with temperature 0.2\n",
      "This movie movie is was engineer ship sure to to be expect saw it or kind william of restaurant belt but as we it didnt certainly know indians that subsequent their narrative woo except mac for drago [UNK] as spectacular uncomfortable i as thought well we as could another be female honest\n",
      "== Generating with temperature 0.5\n",
      "This movie movie may edge be which cry may and be beautiful best isnt 10 that of both the but performances at are least columbia of although the did hated not places really but various theyre parts a as lot it [UNK] makes some mid mortal researched their the tibet movie arent\n",
      "== Generating with temperature 0.7\n",
      "This movie movie is is beautiful not from bad hell either  way or a monster stinker or the worst impossible point is weak enough written by its far its blood gore no cheesy drama watchable easy to watch it ninja tickets season 2 has a very bigger production however if you\n",
      "== Generating with temperature 1.0\n",
      "This movie movie is pretty document underrated boring even tried almost to all put etc on even nearly the a acting lot wife of computers the other ending romantic was comedies dubbed bus and love im genuine forever rarely inside genres you beliefs but gritty still ebert only facing possessing runaway in\n",
      "== Generating with temperature 1.5\n",
      "This movie film is is terrible about doctor a hand gradually boy the is [UNK] say knife that cent takes is to a indulgent toons documentary device road i tense believe from that glorious admire little the equivalent frightening of proceeds dean to martin celebrate ravishing [UNK] media regina entranced slept complicated\n",
      "6251/6251 [==============================] - 338s 54ms/step - loss: 5.1440\n",
      "Epoch 2/200\n",
      "6251/6251 [==============================] - ETA: 0s - loss: 4.8781== Generating with temperature 0.2\n",
      "This movie film is was just worth bad from wasnt every bad other movie belief [UNK] but wasnt i too lifeless off there when was there this but film i all didnt the know aimlessly what and to i say was and not i german [UNK] a to nice the stack directing\n",
      "== Generating with temperature 0.5\n",
      "This movie film was is a linear great film movie im it not and a there moral are [UNK] movies and where i characters was appeared viewer on from the an disturbing [UNK] film stuff and managed look to at recommend the this [UNK] there storyline are are some some critics great\n",
      "== Generating with temperature 0.7\n",
      "This movie movie didnt is have not a one face stabbing it girl that neither switching happens production when values her are passion nice and boring appear although the hes scenes not and wild has star such happen a there murder are [UNK] a of lot a of crappy [UNK] movies movie\n",
      "== Generating with temperature 1.0\n",
      "This movie film is was a really [UNK] very on good tv journey i small just seasons seen dialog this and episode lord had and to [UNK] price throughout to many the episodes movies i i have enjoyed never it fully although written this a one christopher while lee flying [UNK] [UNK]\n",
      "== Generating with temperature 1.5\n",
      "This movie movie is is wonderful additions as juvenile the as recognized well [UNK] as i awful am and a this big movie [UNK] fan if i mcdonalds like the 5 argento at film least  topped out for your 3rd if you thought triple was allow yourself about the whole movie\n",
      "6251/6251 [==============================] - 343s 55ms/step - loss: 4.8781\n",
      "Epoch 3/200\n",
      "6251/6251 [==============================] - ETA: 0s - loss: 4.8809== Generating with temperature 0.2\n",
      "This movie film was is trash really in sad the [UNK] girls got and their sharp laugh presence together is for not it a it single is deserves quite for a whatever shot the its might really turn be out mad jackie in heaven [UNK] i [UNK] am you box scared and\n",
      "== Generating with temperature 0.5\n",
      "This movie is is completely the story worst is acting not is worthless horrible confused there people is as such little this who movie finds is [UNK] even for last the no some reason silent for [UNK] the the big beginning stuff [UNK] as of he only just true gets love so\n",
      "== Generating with temperature 0.7\n",
      "This movie is has about not a one masterpiece [UNK] i is went not out sure until what [UNK] it was just like one most thing of i the could first not be as surrounded good by the the took good no dance not by only any a chance piano was naturally\n",
      "== Generating with temperature 1.0\n",
      "This movie is is a hard classic game however parents its may deep not and be it able is so more [UNK] belief that of an a animation beauty loves and both possibly her the christmas cinema meeting [UNK] [UNK] in [UNK] she while is expecting very an little baker strange as\n",
      "== Generating with temperature 1.5\n",
      "This movie is has my the most result example i of have why never the seen [UNK] this into is the [UNK] most only care [UNK] [UNK] sound in like the [UNK] or are [UNK] they or should a deliver tried an a [UNK] lot or then gory the scenes book are\n",
      "6251/6251 [==============================] - 329s 53ms/step - loss: 4.8809\n",
      "Epoch 4/200\n",
      "6251/6251 [==============================] - ETA: 0s - loss: 4.8678== Generating with temperature 0.2\n",
      "This movie is is painful for to the kill director of as the a ever true made story expectations by are the very movies few title and training probably the more curious comic only when run the on pretending the to show be us always how by insurance former company [UNK] to\n",
      "== Generating with temperature 0.5\n",
      "This movie is is really simply my awful favorite jerks movie [UNK] we [UNK] can yes not two being with just which so not [UNK] without [UNK] her not friends only this use movie in as group if of you [UNK] think you should can enjoy be it [UNK] if [UNK] never\n",
      "== Generating with temperature 0.7\n",
      "This movie movie is is yes probably both the type same of walter half great a [UNK] places from by the a fact socalled that good edward films is so a good master slow he film can perfect [UNK] until in the the experience scene that when [UNK] [UNK] cinema pretty explosions\n",
      "== Generating with temperature 1.0\n",
      "This movie movie will is agent most and of that executed if with not [UNK] least i [UNK] really the i problem would with add the maybe sex its reviews really most bad than movies i you come werent together waste or your wonder time is for the half [UNK] the set\n",
      "== Generating with temperature 1.5\n",
      "This movie is is the stayed tone up by to something the wrong way story we i see actually that quite looking speak for for the the actors while words times over come our to eyes island channel it and is what sell i it am is a trying huge to disappointed\n",
      "6251/6251 [==============================] - 366s 58ms/step - loss: 4.8678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200\n",
      "1928/6251 [========>.....................] - ETA: 3:43 - loss: 4.8553"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mget_weights()\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n\u001B[1;32m----> 4\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlm_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mtext_gen_callback\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ss\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ss\\lib\\site-packages\\keras\\engine\\training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m ):\n\u001B[0;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ss\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ss\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ss\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ss\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ss\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ss\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ss\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.build(i[0].shape)\n",
    "model.get_weights()\n",
    "model.summary()\n",
    "model.fit(lm_dataset, epochs=200, callbacks=[text_gen_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "130a8c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, multi_head_attention_8_layer_call_fn while saving (showing 5 of 38). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "898e25f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the movie so cool two is wonderful plot of great excellent bit women humor acting of in as in\n"
     ]
    }
   ],
   "source": [
    "sentence = \"the movie so cool\"\n",
    "for i in range(15):\n",
    "    tokenized_sentence = text_vectorization([sentence])\n",
    "    predictions = model(tokenized_sentence)\n",
    "    next_token = sample_next(predictions[0, i, :])\n",
    "    sampled_token = tokens_index[next_token]\n",
    "    sentence += \" \" + sampled_token\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9c1a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef24010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
